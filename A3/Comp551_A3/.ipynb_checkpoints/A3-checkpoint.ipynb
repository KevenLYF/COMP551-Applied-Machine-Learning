{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yufei Liu 260561054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import string\n",
    "import collections\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "TOP = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dataset):\n",
    "    translator=str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    filepath = Path(dataset)\n",
    "    text = filepath.read_text()\n",
    "    text = text.translate(translator).lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate vocabulary datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genVocabFile(source, target):\n",
    "    dataset = preprocessing(source)\n",
    "    freqwords = collections.Counter()\n",
    "    for reviews in dataset.splitlines():\n",
    "        words = reviews.split()[:-1]\n",
    "        freqwords.update(words)\n",
    "    freqwords = freqwords.most_common(TOP)\n",
    "    with open(target, \"w\", newline='') as textfile:\n",
    "        writer = csv.writer(textfile, delimiter='\\t', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for i in range(len(freqwords)):\n",
    "            writer.writerow([freqwords[i][0], i + 1, freqwords[i][1]])\n",
    "\n",
    "def genVocab(source):\n",
    "    dataset = preprocessing(source)\n",
    "    freqwords = collections.Counter()\n",
    "    for reviews in dataset.splitlines():\n",
    "        words = reviews.split()[:-1]\n",
    "        freqwords.update(words)\n",
    "    freqwords = freqwords.most_common(TOP)\n",
    "    vocab = {}\n",
    "    for i in range(len(freqwords)):\n",
    "        vocab[freqwords[i][0]] = (i + 1, freqwords[i][1])\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate review ID datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildIDFile(source, vocab, target):\n",
    "    dataset = preprocessing(source)\n",
    "    reviewByID = []\n",
    "    count = 0\n",
    "    for reviews in dataset.splitlines():\n",
    "        if (len(reviews) == 0):\n",
    "            continue\n",
    "        words = reviews.split()\n",
    "        if not (words[-1].isdigit()):\n",
    "            continue\n",
    "        score = int(words[len(words) - 1])\n",
    "        row = []\n",
    "        for i in range(len(words) - 1):\n",
    "            id = vocab.get(words[i], -1)\n",
    "            if (id != -1):\n",
    "                row.append(id[0])\n",
    "        if (len(row) > 0):\n",
    "            row.append(score)\n",
    "            reviewByID.append(row)\n",
    "    with open(target, \"w\", newline='') as textfile:\n",
    "        writer = csv.writer(textfile, delimiter=' ')\n",
    "        for i in range(len(reviewByID)):\n",
    "            row = []\n",
    "            score = reviewByID[i][-1]\n",
    "            for j in range(len(reviewByID[i]) - 1):\n",
    "                row.append(reviewByID[i][j])\n",
    "            row.append('\\t' + str(score))\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yelpVocab = genVocab(\"hwk3_datasets/yelp-train.txt\")\n",
    "# imdbVocab = genVocab(\"hwk3_datasets/IMDB-train.txt\")\n",
    "\n",
    "# genVocabFile(\"hwk3_datasets/yelp-train.txt\", \"output_datasets/yelp-vocab.txt\")\n",
    "# buildIDFile(\"hwk3_datasets/yelp-train.txt\", yelpVocab, \"output_datasets/yelp-train.txt\")\n",
    "# buildIDFile(\"hwk3_datasets/yelp-test.txt\", yelpVocab, \"output_datasets/yelp-test.txt\")\n",
    "# buildIDFile(\"hwk3_datasets/yelp-valid.txt\", yelpVocab, \"output_datasets/yelp-valid.txt\")\n",
    "#\n",
    "# genVocabFile(\"hwk3_datasets/IMDB-train.txt\", \"output_datasets/IMDB-vocab.txt\")\n",
    "# buildIDFile(\"hwk3_datasets/IMDB-train.txt\", imdbVocab, \"output_datasets/IMDB-train.txt\")\n",
    "# buildIDFile(\"hwk3_datasets/IMDB-test.txt\", imdbVocab, \"output_datasets/IMDB-test.txt\")\n",
    "# buildIDFile(\"hwk3_datasets/IMDB-valid.txt\", imdbVocab, \"output_datasets/IMDB-valid.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read reviews and ratings from the generated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReviews(datapath):\n",
    "    review = []\n",
    "    scores = []\n",
    "    filepath = Path(datapath)\n",
    "    text = filepath.read_text()\n",
    "    for comments in text.splitlines():\n",
    "        row = []\n",
    "        IDs = comments.split()[:-1]\n",
    "        score = comments.split()[-1]\n",
    "        for i in range(len(IDs)):\n",
    "            row.append(int(IDs[i]))\n",
    "        review.append(row)\n",
    "        scores.append(score)\n",
    "\n",
    "    return (review, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build binary bag of words, which creates a 10000 dimension vector for each review in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildBinaryBOW(reviewsID):\n",
    "    fVector = []\n",
    "    for i in range(len(reviewsID)):\n",
    "        row = [0] * TOP\n",
    "        uniqueSet = set()\n",
    "        for j in range(len(reviewsID[i])):\n",
    "            pos = reviewsID[i][j]\n",
    "            if pos in uniqueSet:\n",
    "                continue\n",
    "            row[pos] = 1\n",
    "            uniqueSet.add(pos)\n",
    "        fVector.append(row)\n",
    "    return fVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build frequency bag of words, the value in a feature vector would be the occurance frequency of that word. The values of a feature vectore sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildFreqBOW(reviewsID):\n",
    "    fVector = []\n",
    "    for i in range(len(reviewsID)):\n",
    "        uniqueSet = set()\n",
    "        row = [0] * TOP\n",
    "        for j in range(len(reviewsID[i])):\n",
    "            pos = reviewsID[i][j]\n",
    "            if pos in uniqueSet:\n",
    "                continue\n",
    "            count = reviewsID[i].count(pos)\n",
    "            row[pos] = count/len(reviewsID[i])\n",
    "            uniqueSet.add(pos)\n",
    "        fVector.append(row)\n",
    "    return fVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two baseline classifiers by using scikit-learn DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomClf(X_train, y_train, X_test, y_test):\n",
    "    clf_uniform = DummyClassifier(strategy='uniform')\n",
    "    clf_uniform.fit(X_train, y_train)\n",
    "    predict_uniform = []\n",
    "    for i in range(len(X_test)):\n",
    "        res_uniform = clf_uniform.predict([X_test[i]])\n",
    "        predict_uniform.append(res_uniform)\n",
    "    print('Uniform Random F1 Measure = ' + str(metrics.f1_score(y_test, predict_uniform, average='micro')))\n",
    "\n",
    "def majorityClf(X_train, y_train, X_test, y_test):\n",
    "    clf_mostFreq = DummyClassifier(strategy='most_frequent')\n",
    "    clf_mostFreq.fit(X_train, y_train)\n",
    "    predict_mostFreq = []\n",
    "    for i in range(len(X_test)):\n",
    "        res_mostFreq = clf_mostFreq.predict([X_test[i]])\n",
    "        predict_mostFreq.append(res_mostFreq)\n",
    "    print('Majority Class F1 Measure = ' + str(metrics.f1_score(y_test, predict_mostFreq, average='micro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for trainning and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainReviews = getReviews(\"output_datasets/yelp-train.txt\")\n",
    "trainX = buildBinaryBOW(trainReviews[0])\n",
    "trainY = trainReviews[1]\n",
    "\n",
    "validReviews = getReviews(\"output_datasets/yelp-valid.txt\")\n",
    "validX = buildBinaryBOW(validReviews[0])\n",
    "validY = validReviews[1]\n",
    "\n",
    "testReviews = getReviews(\"output_datasets/yelp-test.txt\")\n",
    "testX = buildBinaryBOW(testReviews[0])\n",
    "testY = testReviews[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Random F1 Measure = 0.181\n",
      "Majority Class F1 Measure = 0.351\n"
     ]
    }
   ],
   "source": [
    "randomClf(trainX, trainY, testX, testY)\n",
    "majorityClf(trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting function to visualize the training process, to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainningProcess(dataset):\n",
    "    a = np.array(dataset,dtype='float')\n",
    "    a = np.transpose(a)\n",
    "    plt.plot(a[1], a[0], 'ro')\n",
    "    plt.title('Finding Hyper Parameter')\n",
    "    plt.xlabel('Hyper Parameter')\n",
    "    plt.ylabel('F1 Measure')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BernoulliNativeBayes(X_train, y_train, X_test, y_test, a):\n",
    "    clf = BernoulliNB(alpha=a)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predict = []\n",
    "    for i in range(len(X_test)):\n",
    "        res = clf.predict([X_test[i]])\n",
    "        predict.append(res)\n",
    "    f1 = metrics.f1_score(y_test, predict, average='micro')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for finding the best smoothing parameter alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAlpha_BNB(X_train, y_train, X_test, y_test):\n",
    "    a = 1.0\n",
    "    best_alpha = 1.0\n",
    "    best_f1 = 0\n",
    "    hyperP = []\n",
    "    for i in range(30):\n",
    "        f1 = BernoulliNativeBayes(X_train, y_train, X_test, y_test, a)\n",
    "        hyperP.append([f1, a])\n",
    "        if (f1 > best_f1):\n",
    "            best_f1 = f1\n",
    "            best_alpha = a\n",
    "        a *= 0.8\n",
    "    hyperP.sort()\n",
    "    plotTrainningProcess(hyperP)\n",
    "    print(\"The best smoothing parameter alpha = {} \\n F1 measure  = {}\".format(best_alpha, best_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the best alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best smoothing parameter alpha = 0.009223372036854787 \n",
      " F1 measure  = 0.421\n"
     ]
    }
   ],
   "source": [
    "findAlpha_BNB(trainX, trainY, validX, validY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the best alpha and predit the test dataset with alpha = 0.009223372036854787 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BBOW) Training F1 Measure of Bernoulli NB with best hyper-parameter = 0.7382857142857144\n",
      "(BBOW) Validation F1 Measure of Bernoulli NB with best hyper-parameter = 0.421\n",
      "(BBOW) Testing F1 Measure of Bernoulli NB with best hyper-parameter = 0.4455\n"
     ]
    }
   ],
   "source": [
    "BBOW_F1_BNB_train = BernoulliNativeBayes(trainX, trainY, trainX, trainY, 0.009223372036854787)\n",
    "print(\"(BBOW) Training F1 Measure of Bernoulli NB with best hyper-parameter = {}\".format(BBOW_F1_BNB_train))\n",
    "BBOW_F1_BNB_valid = BernoulliNativeBayes(trainX, trainY, validX, validY, 0.009223372036854787)\n",
    "print(\"(BBOW) Validation F1 Measure of Bernoulli NB with best hyper-parameter = {}\".format(BBOW_F1_BNB_valid))\n",
    "BBOW_F1_BNB_test = BernoulliNativeBayes(trainX, trainY, testX, testY, 0.009223372036854787)\n",
    "print(\"(BBOW) Testing F1 Measure of Bernoulli NB with best hyper-parameter = {}\".format(BBOW_F1_BNB_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def decisionTree(X_train, y_train, X_test, y_test, min_sample, maxDepth):\n",
    "    clf = DecisionTreeClassifier(min_samples_split=min_sample, max_depth=maxDepth)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predict = []\n",
    "    for i in range(len(X_test)):\n",
    "        res = clf.predict([X_test[i]])\n",
    "        predict.append(res)\n",
    "    f1 = metrics.f1_score(y_test, predict, average='micro')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findHyperP_DT(X_train, y_train, X_test, y_test):\n",
    "    best_f1 = 0\n",
    "    best_max = 1\n",
    "    best_min_sample = 1.0\n",
    "    max_depth = 1\n",
    "    for i in range(10):\n",
    "        min_sample_split = 1.0\n",
    "        for i in range(15):\n",
    "            f1 = decisionTree(X_train, y_train, X_test, y_test, min_sample_split, max_depth)\n",
    "            if (f1 > best_f1):\n",
    "                best_f1 = f1\n",
    "                best_min_sample = min_sample_split\n",
    "                best_max = max_depth\n",
    "            min_sample_split *= 0.7\n",
    "        max_depth += 1\n",
    "    print(\"The best F1 measure  = {} \\nmax_depth = {} \\nmin_sample_split = {}\".format(best_f1, best_max, best_min_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best F1 measure  = 0.418 \n",
      " max_depth = 10 \n",
      " min_sample_split = 0.04035360699999998\n"
     ]
    }
   ],
   "source": [
    "findHyperP_DT(trainX, trainY, validX, validY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the best max_depth and min_sample_split on the test set with max_depth = 10 and min_sample_split = 0.04035360699999998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BBOW) Training F1 Measure of Decision Tree with best hyper-parameter = 0.46514285714285714\n",
      "(BBOW) Validation F1 Measure of Decision Tree with best hyper-parameter = 0.41999999999999993\n",
      "(BBOW) Testing F1 Measure of Decision Tree with best hyper-parameter = 0.418\n"
     ]
    }
   ],
   "source": [
    "BBOW_F1_DT_train = decisionTree(trainX, trainY, trainX, trainY, 0.04035360699999998, 10)\n",
    "print(\"(BBOW) Training F1 Measure of Decision Tree with best hyper-parameter = {}\".format(BBOW_F1_DT_train))\n",
    "BBOW_F1_DT_valid = decisionTree(trainX, trainY, validX, validY, 0.04035360699999998, 10)\n",
    "print(\"(BBOW) Validation F1 Measure of Decision Tree with best hyper-parameter = {}\".format(BBOW_F1_DT_valid))\n",
    "BBOW_F1_DT_test = decisionTree(trainX, trainY, testX, testY, 0.04035360699999998, 10)\n",
    "print(\"(BBOW) Testing F1 Measure of Decision Tree with best hyper-parameter = {}\".format(BBOW_F1_DT_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearSVM(X_train, y_train, X_test, y_test, C, dual):\n",
    "    clf = LinearSVC(C=C,dual=dual)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predict = []\n",
    "    for i in range(len(X_test)):\n",
    "        res = clf.predict([X_test[i]])\n",
    "        predict.append(res)\n",
    "    f1 = metrics.f1_score(y_test, predict, average='micro')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 measure = 0.513 \n",
      "C = 0.009223372036854787\n",
      "Dual = False\n"
     ]
    }
   ],
   "source": [
    "c = 1.0\n",
    "best_f1 = 0\n",
    "bestC = 1.0\n",
    "best_dual = False\n",
    "for i in range(25):\n",
    "    dual = False\n",
    "    f1 = linearSVM(trainX, trainY, validX, validY,c, dual)\n",
    "    if (f1 > best_f1):\n",
    "        best_f1 = f1\n",
    "        bestC = c\n",
    "        best_dual = dual\n",
    "    dual = True\n",
    "    f1 = linearSVM(trainX, trainY, validX, validY, c, dual)\n",
    "    if (f1 > best_f1):\n",
    "        best_f1 = f1\n",
    "        bestC = c\n",
    "        best_dual = dual\n",
    "    c *= 0.8\n",
    "\n",
    "print(\"The F1 measure = {} \\nC = {}\\nDual = {}\".format(best_f1, bestC, best_dual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the best hyper parameters with C = 0.009223372036854787 and dual = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BBOW) Training F1 Measure of Linear SVM with best hyper-parameter = 0.8435714285714284\n",
      "(BBOW) Validation F1 Measure of Linear SVM with best hyper-parameter = 0.513\n",
      "(BBOW) Testing F1 Measure of Linear SVM with best hyper-parameter = 0.5085\n"
     ]
    }
   ],
   "source": [
    "BBOW_F1_SVM_train = linearSVM(trainX, trainY, trainX, trainY, 0.009223372036854787, False)\n",
    "print(\"(BBOW) Training F1 Measure of Linear SVM with best hyper-parameter = {}\".format(BBOW_F1_SVM_train))\n",
    "BBOW_F1_SVM_valid = linearSVM(trainX, trainY, validX, validY, 0.009223372036854787, False)\n",
    "print(\"(BBOW) Validation F1 Measure of Linear SVM with best hyper-parameter = {}\".format(BBOW_F1_SVM_valid))\n",
    "BBOW_F1_SVM_test = linearSVM(trainX, trainY, testX, testY, 0.009223372036854787, False)\n",
    "print(\"(BBOW) Testing F1 Measure of Linear SVM with best hyper-parameter = {}\".format(BBOW_F1_SVM_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainReviews = getReviews(\"output_datasets/yelp-train.txt\")\n",
    "trainX = buildFreqBOW(trainReviews[0])\n",
    "trainY = trainReviews[1]\n",
    "\n",
    "validReviews = getReviews(\"output_datasets/yelp-valid.txt\")\n",
    "validX = buildFreqBOW(validReviews[0])\n",
    "validY = validReviews[1]\n",
    "\n",
    "testReviews = getReviews(\"output_datasets/yelp-test.txt\")\n",
    "testX = buildFreqBOW(testReviews[0])\n",
    "testY = testReviews[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Native Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianNativeBayes(X_train, y_train, X_test, y_test):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    predict = []\n",
    "    for i in range(len(X_test)):\n",
    "        res = clf.predict([X_test[i]])\n",
    "        predict.append(res)\n",
    "    f1 = metrics.f1_score(y_test, predict, average='micro')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(FBOW) Training F1 Measure of Gaussian NB = 0.8014285714285714\n",
      "(FBOW) Validation F1 Measure of Gaussian NB = 0.3\n",
      "(FBOW) Testing F1 Measure of Gaussian NB = 0.312\n"
     ]
    }
   ],
   "source": [
    "FBOW_F1_GNB_train = GaussianNativeBayes(trainX, trainY, trainX, trainY)\n",
    "print(\"(FBOW) Training F1 Measure of Gaussian NB = {}\".format(FBOW_F1_GNB_train))\n",
    "FBOW_F1_GNB_valid = GaussianNativeBayes(trainX, trainY, validX, validY)\n",
    "print(\"(FBOW) Validation F1 Measure of Gaussian NB = {}\".format(FBOW_F1_GNB_valid))\n",
    "FBOW_F1_GNB_test = GaussianNativeBayes(trainX, trainY, testX, testY)\n",
    "print(\"(FBOW) Testing F1 Measure of Gaussian NB = {}\".format(FBOW_F1_GNB_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch_DT(X_train, y_train):\n",
    "    minSample_range = np.logspace(16, 0, num=15, base=0.8)\n",
    "    maxDepth_range = range(1, 15)\n",
    "    param_grid = dict(min_samples_split=minSample_range, max_depth=maxDepth_range)\n",
    "    DT = DecisionTreeClassifier(min_samples_split=minSample_range, max_depth=maxDepth_range)\n",
    "    gs = GridSearchCV(DT, param_grid, scoring='f1_micro', cv=3, n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_score = gs.best_score_\n",
    "    best_param = gs.best_params_\n",
    "    print(\"The best F1 measure  = {} \\nmax_depth = {} \\nmin_sample_split = {}\".format(best_score, best_param.get('min_samples_split'), best_param.get('max_depth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch_DT(trainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the best min_sample_split on the test set with min_sample_split = 0.04035360699999998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FBOW_F1_DT_train = decisionTree(trainX, trainY, trainX, trainY, 0.04035360699999998)\n",
    "print(\"(FBOW) Training F1 Measure of Decision Tree with best hyper-parameter = {}\".format(FBOW_F1_DT_train))\n",
    "FBOW_F1_DT_valid = decisionTree(trainX, trainY, validX, validY, 0.04035360699999998)\n",
    "print(\"(FBOW) Validation F1 Measure of Decision Tree with best hyper-parameter = {}\".format(FBOW_F1_DT_valid))\n",
    "FBOW_F1_DT_test = decisionTree(trainX, trainY, testX, testY, 0.04035360699999998)\n",
    "print(\"(FBOW) Testing F1 Measure of Decision Tree with best hyper-parameter = {}\".format(FBOW_F1_DT_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridSearch_SVM(X_train, y_train):\n",
    "    c_range = np.logspace(-5, -20, num=15, base=0.8)\n",
    "    d_range = [True, False]\n",
    "    param_grid = dict(C=c_range, dual=d_range)\n",
    "    svm = LinearSVC(C=c_range, dual=d_range)\n",
    "    gs = GridSearchCV(svm, param_grid, scoring='f1_micro', cv=3, n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_score = gs.best_score_\n",
    "    best_param = gs.best_params_\n",
    "    print(\"The F1 measure = {} \\nC = {}\\nDual = {}\".format(best_score, best_param.get('C'), best_param.get('dual')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridSearch_DT(trainX, trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the best hyper parameters with C = 0.009223372036854787 and dual = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FBOW_F1_SVM_train = linearSVM(trainX, trainY, trainX, trainY, 0.009223372036854787, False)\n",
    "print(\"(FBOW) Training F1 Measure of Linear SVM with best hyper-parameter = {}\".format(FBOW_F1_SVM_train))\n",
    "FBOW_F1_SVM_valid = linearSVM(trainX, trainY, validX, validY, 0.009223372036854787, False)\n",
    "print(\"(FBOW) Validation F1 Measure of Linear SVM with best hyper-parameter = {}\".format(FBOW_F1_SVM_valid))\n",
    "FBOW_F1_SVM_test = linearSVM(trainX, trainY, testX, testY, 0.009223372036854787, False)\n",
    "print(\"(FBOW) Testing F1 Measure of Linear SVM with best hyper-parameter = {}\".format(FBOW_F1_SVM_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainReviews = getReviews(\"output_datasets/IMDB-train.txt\")\n",
    "trainX = buildBinaryBOW(trainReviews[0])\n",
    "trainY = trainReviews[1]\n",
    "\n",
    "validReviews = getReviews(\"output_datasets/IMDB-valid.txt\")\n",
    "validX = buildBinaryBOW(validReviews[0])\n",
    "validY = validReviews[1]\n",
    "\n",
    "testReviews = getReviews(\"output_datasets/IMDB-test.txt\")\n",
    "testX = buildBinaryBOW(testReviews[0])\n",
    "testY = testReviews[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base line classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomClf(trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findAlpha_BNB(trainX, trainY, validX, validY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the best alpha and predit the test dataset with alpha = 0.009223372036854787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBOW_F1_BNB_train = BernoulliNativeBayes(trainX, trainY, trainX, trainY, 0.009223372036854787)\n",
    "print(\"(BBOW) Training F1 Measure of Bernoulli NB with best hyper-parameter = {}\".format(BBOW_F1_BNB_train))\n",
    "BBOW_F1_BNB_valid = BernoulliNativeBayes(trainX, trainY, validX, validY, 0.009223372036854787)\n",
    "print(\"(BBOW) Validation F1 Measure of Bernoulli NB with best hyper-parameter = {}\".format(BBOW_F1_BNB_valid))\n",
    "BBOW_F1_BNB_test = BernoulliNativeBayes(trainX, trainY, testX, testY, 0.009223372036854787)\n",
    "print(\"(BBOW) Testing F1 Measure of Bernoulli NB with best hyper-parameter = {}\".format(BBOW_F1_BNB_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
