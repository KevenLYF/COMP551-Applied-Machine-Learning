{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yufei Liu 260561054"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import string\n",
    "import collections\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "TOP = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dataset):\n",
    "    translator=str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    filepath = Path(dataset)\n",
    "    text = filepath.read_text()\n",
    "    text = text.translate(translator).lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate vocabulary datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genVocabFile(source, target):\n",
    "    dataset = preprocessing(source)\n",
    "    freqwords = collections.Counter()\n",
    "    for reviews in dataset.splitlines():\n",
    "        words = reviews.split()[:-1]\n",
    "        freqwords.update(words)\n",
    "    freqwords = freqwords.most_common(TOP)\n",
    "    with open(target, \"w\", newline='') as textfile:\n",
    "        writer = csv.writer(textfile, delimiter='\\t', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "        for i in range(len(freqwords)):\n",
    "            writer.writerow([freqwords[i][0], i + 1, freqwords[i][1]])\n",
    "\n",
    "def genVocab(source):\n",
    "    dataset = preprocessing(source)\n",
    "    freqwords = collections.Counter()\n",
    "    for reviews in dataset.splitlines():\n",
    "        words = reviews.split()[:-1]\n",
    "        freqwords.update(words)\n",
    "    freqwords = freqwords.most_common(TOP)\n",
    "    vocab = {}\n",
    "    for i in range(len(freqwords)):\n",
    "        vocab[freqwords[i][0]] = (i + 1, freqwords[i][1])\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate review ID datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildIDFile(source, vocab, target):\n",
    "    dataset = preprocessing(source)\n",
    "    reviewByID = []\n",
    "    count = 0\n",
    "    for reviews in dataset.splitlines():\n",
    "        if (len(reviews) == 0):\n",
    "            continue\n",
    "        words = reviews.split()\n",
    "        if not (words[-1].isdigit()):\n",
    "            continue\n",
    "        score = int(words[len(words) - 1])\n",
    "        row = []\n",
    "        for i in range(len(words) - 1):\n",
    "            id = vocab.get(words[i], -1)\n",
    "            if (id != -1):\n",
    "                row.append(id[0])\n",
    "        if (len(row) > 0):\n",
    "            row.append(score)\n",
    "            reviewByID.append(row)\n",
    "    with open(target, \"w\", newline='') as textfile:\n",
    "        writer = csv.writer(textfile, delimiter=' ')\n",
    "        for i in range(len(reviewByID)):\n",
    "            row = []\n",
    "            score = reviewByID[i][-1]\n",
    "            for j in range(len(reviewByID[i]) - 1):\n",
    "                row.append(reviewByID[i][j])\n",
    "            row.append('\\t' + str(score))\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yelpVocab = genVocab(\"hwk3_datasets/yelp-train.txt\")\n",
    "# imdbVocab = genVocab(\"hwk3_datasets/IMDB-train.txt\")\n",
    "\n",
    "# genVocabFile(\"hwk3_datasets/yelp-train.txt\", \"output_datasets/yelp-vocab.txt\")\n",
    "# buildIDFile(\"hwk3_datasets/yelp-train.txt\", yelpVocab, \"output_datasets/yelp-train.txt\")\n",
    "# buildIDFile(\"hwk3_datasets/yelp-test.txt\", yelpVocab, \"output_datasets/yelp-test.txt\")\n",
    "# buildIDFile(\"hwk3_datasets/yelp-valid.txt\", yelpVocab, \"output_datasets/yelp-valid.txt\")\n",
    "#\n",
    "# genVocabFile(\"hwk3_datasets/IMDB-train.txt\", \"output_datasets/IMDB-vocab.txt\")\n",
    "# buildIDFile(\"hwk3_datasets/IMDB-train.txt\", imdbVocab, \"output_datasets/IMDB-train.txt\")\n",
    "# buildIDFile(\"hwk3_datasets/IMDB-test.txt\", imdbVocab, \"output_datasets/IMDB-test.txt\")\n",
    "# buildIDFile(\"hwk3_datasets/IMDB-valid.txt\", imdbVocab, \"output_datasets/IMDB-valid.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read reviews and ratings from the generated datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReviews(datapath):\n",
    "    review = []\n",
    "    scores = []\n",
    "    filepath = Path(datapath)\n",
    "    text = filepath.read_text()\n",
    "    for comments in text.splitlines():\n",
    "        row = []\n",
    "        IDs = comments.split()[:-1]\n",
    "        score = comments.split()[-1]\n",
    "        for i in range(len(IDs)):\n",
    "            row.append(int(IDs[i]))\n",
    "        review.append(row)\n",
    "        scores.append(score)\n",
    "\n",
    "    return (review, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build binary bag of words, which creates a 10000 dimension vector for each review in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildBinaryBOW(reviewsID):\n",
    "    fVector = []\n",
    "    for i in range(len(reviewsID)):\n",
    "        row = [0] * TOP\n",
    "        uniqueSet = set()\n",
    "        for j in range(len(reviewsID[i])):\n",
    "            pos = reviewsID[i][j]\n",
    "            if pos in uniqueSet:\n",
    "                continue\n",
    "            row[pos] = 1\n",
    "            uniqueSet.add(pos)\n",
    "        fVector.append(row)\n",
    "    return fVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build frequency bag of words, the value in a feature vector would be the occurance frequency of that word. The values of a feature vectore sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildFreqBOW(reviewsID):\n",
    "    fVector = []\n",
    "    for i in range(len(reviewsID)):\n",
    "        uniqueSet = set()\n",
    "        row = [0] * TOP\n",
    "        for j in range(len(reviewsID[i])):\n",
    "            pos = reviewsID[i][j]\n",
    "            if pos in uniqueSet:\n",
    "                continue\n",
    "            count = reviewsID[i].count(pos)\n",
    "            row[pos] = count/len(reviewsID[i])\n",
    "            uniqueSet.add(pos)\n",
    "        fVector.append(row)\n",
    "    return fVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two baseline classifiers by using scikit-learn DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomClf(X_train, y_train, X_test, y_test):\n",
    "    clf_uniform = DummyClassifier(strategy='uniform')\n",
    "    clf_uniform.fit(X_train, y_train)\n",
    "    predict_uniform = []\n",
    "    for i in range(len(X_test)):\n",
    "        res_uniform = clf_uniform.predict([X_test[i]])\n",
    "        predict_uniform.append(res_uniform)\n",
    "    print('Uniform Random F1 Measure = ' + str(metrics.f1_score(y_test, predict_uniform, average='micro')))\n",
    "\n",
    "def majorityClf(X_train, y_train, X_test, y_test):\n",
    "    clf_mostFreq = DummyClassifier(strategy='most_frequent')\n",
    "    clf_mostFreq.fit(X_train, y_train)\n",
    "    predict_mostFreq = []\n",
    "    for i in range(len(X_test)):\n",
    "        res_mostFreq = clf_mostFreq.predict([X_test[i]])\n",
    "        predict_mostFreq.append(res_mostFreq)\n",
    "    print('Majority Class F1 Measure = ' + str(metrics.f1_score(y_test, predict_mostFreq, average='micro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare for trainning and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainReviews = getReviews(\"output_datasets/yelp-train.txt\")\n",
    "trainX = buildBinaryBOW(trainReviews[0])\n",
    "trainY = trainReviews[1]\n",
    "\n",
    "validReviews = getReviews(\"output_datasets/yelp-valid.txt\")\n",
    "validX = buildBinaryBOW(validReviews[0])\n",
    "validY = validReviews[1]\n",
    "\n",
    "testReviews = getReviews(\"output_datasets/yelp-test.txt\")\n",
    "testX = buildBinaryBOW(testReviews[0])\n",
    "testY = testReviews[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Random F1 Measure = 0.2095\n",
      "Majority Class F1 Measure = 0.351\n"
     ]
    }
   ],
   "source": [
    "randomClf(trainX, trainY, testX, testY)\n",
    "majorityClf(trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ploting function to visualize the training process, to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainningProcess(dataset):\n",
    "    a = np.array(dataset,dtype='float')\n",
    "    a = np.transpose(a)\n",
    "    plt.plot(a[1], a[0], 'ro')\n",
    "    plt.title('Finding Hyper Parameter')\n",
    "    plt.xlabel('Hyper Parameter')\n",
    "    plt.ylabel('F1 Measure')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BernoulliNativeBayes(X_train, y_train, X_test, y_test, a):\n",
    "    clf = BernoulliNB(alpha=a)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predict = []\n",
    "    for i in range(len(X_test)):\n",
    "        res = clf.predict([X_test[i]])\n",
    "        predict.append(res)\n",
    "    f1 = metrics.f1_score(y_test, predict, average='micro')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for finding the best smoothing parameter alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAlpha_BNB(X_train, y_train, X_test, y_test):\n",
    "    a = 1.0\n",
    "    best_alpha = 1.0\n",
    "    best_f1 = 0\n",
    "    hyperP = []\n",
    "    for i in range(25):\n",
    "        f1 = BernoulliNativeBayes(X_train, y_train, X_test, y_test, a)\n",
    "        hyperP.append([f1, a])\n",
    "        if (f1 > best_f1):\n",
    "            best_f1 = f1\n",
    "            best_alpha = a\n",
    "        a *= 0.8\n",
    "    hyperP.sort()\n",
    "    plotTrainningProcess(hyperP)\n",
    "    print(\"The best smoothing parameter alpha = {} \\n F1 measure  = {}\".format(best_alpha, best_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the best alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best smoothing parameter alpha = 0.009223372036854787 \n",
      " F1 measure  = 0.421\n"
     ]
    }
   ],
   "source": [
    "findAlpha_BNB(trainX, trainY, validX, validY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the best alpha and predit the test dataset with alpha = 0.009223372036854787 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BBOW) Training F1 Measure of Bernoulli NB with best hyper-parameter = 0.7382857142857144\n",
      "(BBOW) Validation F1 Measure of Bernoulli NB with best hyper-parameter = 0.421\n",
      "(BBOW) Testing F1 Measure of Bernoulli NB with best hyper-parameter = 0.4455\n"
     ]
    }
   ],
   "source": [
    "BBOW_F1_BNB_train = BernoulliNativeBayes(trainX, trainY, trainX, trainY, 0.009223372036854787)\n",
    "print(\"(BBOW) Training F1 Measure of Bernoulli NB with best hyper-parameter = {}\".format(BBOW_F1_BNB_train))\n",
    "BBOW_F1_BNB_valid = BernoulliNativeBayes(trainX, trainY, validX, validY, 0.009223372036854787)\n",
    "print(\"(BBOW) Validation F1 Measure of Bernoulli NB with best hyper-parameter = {}\".format(BBOW_F1_BNB_valid))\n",
    "BBOW_F1_BNB_test = BernoulliNativeBayes(trainX, trainY, testX, testY, 0.009223372036854787)\n",
    "print(\"(BBOW) Testing F1 Measure of Bernoulli NB with best hyper-parameter = {}\".format(BBOW_F1_BNB_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def decisionTree(X_train, y_train, X_test, y_test, min_sample, maxDepth):\n",
    "    clf = DecisionTreeClassifier(min_samples_split=min_sample, max_depth=maxDepth)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predict = []\n",
    "    for i in range(len(X_test)):\n",
    "        res = clf.predict([X_test[i]])\n",
    "        predict.append(res)\n",
    "    f1 = metrics.f1_score(y_test, predict, average='micro')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findHyperP_DT(X_train, y_train, X_test, y_test):\n",
    "    best_f1 = 0\n",
    "    best_max = 1\n",
    "    best_min_sample = 1.0\n",
    "    max_depth = 1\n",
    "    for i in range(6, 12):\n",
    "        min_sample_split = 0.49\n",
    "        for i in range(10):\n",
    "            f1 = decisionTree(X_train, y_train, X_test, y_test, min_sample_split, max_depth)\n",
    "            if (f1 > best_f1):\n",
    "                best_f1 = f1\n",
    "                best_min_sample = min_sample_split\n",
    "                best_max = max_depth\n",
    "            min_sample_split *= 0.7\n",
    "        max_depth += 1\n",
    "    print(\"The best F1 measure  = {} \\nmax_depth = {} \\nmin_sample_split = {}\".format(best_f1, best_max, best_min_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best F1 measure  = 0.418 \n",
      "max_depth = 10 \n",
      "min_sample_split = 0.04035360699999998\n"
     ]
    }
   ],
   "source": [
    "findHyperP_DT(trainX, trainY, validX, validY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the best max_depth and min_sample_split on the test set with max_depth = 10 and min_sample_split = 0.04035360699999998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BBOW) Training F1 Measure of Decision Tree with best hyper-parameter = 0.46514285714285714\n",
      "(BBOW) Validation F1 Measure of Decision Tree with best hyper-parameter = 0.418\n",
      "(BBOW) Testing F1 Measure of Decision Tree with best hyper-parameter = 0.418\n"
     ]
    }
   ],
   "source": [
    "BBOW_F1_DT_train = decisionTree(trainX, trainY, trainX, trainY, 0.04035360699999998, 10)\n",
    "print(\"(BBOW) Training F1 Measure of Decision Tree with best hyper-parameter = {}\".format(BBOW_F1_DT_train))\n",
    "BBOW_F1_DT_valid = decisionTree(trainX, trainY, validX, validY, 0.04035360699999998, 10)\n",
    "print(\"(BBOW) Validation F1 Measure of Decision Tree with best hyper-parameter = {}\".format(BBOW_F1_DT_valid))\n",
    "BBOW_F1_DT_test = decisionTree(trainX, trainY, testX, testY, 0.04035360699999998, 10)\n",
    "print(\"(BBOW) Testing F1 Measure of Decision Tree with best hyper-parameter = {}\".format(BBOW_F1_DT_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearSVM(X_train, y_train, X_test, y_test, C, dual):\n",
    "    clf = LinearSVC(C=C,dual=dual)\n",
    "    clf.fit(X_train, y_train)\n",
    "    predict = []\n",
    "    for i in range(len(X_test)):\n",
    "        res = clf.predict([X_test[i]])\n",
    "        predict.append(res)\n",
    "    f1 = metrics.f1_score(y_test, predict, average='micro')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 measure = 0.513 \n",
      "C = 0.009223372036854787\n",
      "Dual = False\n"
     ]
    }
   ],
   "source": [
    "c = 1.0\n",
    "best_f1 = 0\n",
    "bestC = 1.0\n",
    "best_dual = False\n",
    "for i in range(25):\n",
    "    dual = False\n",
    "    f1 = linearSVM(trainX, trainY, validX, validY,c, dual)\n",
    "    if (f1 > best_f1):\n",
    "        best_f1 = f1\n",
    "        bestC = c\n",
    "        best_dual = dual\n",
    "    dual = True\n",
    "    f1 = linearSVM(trainX, trainY, validX, validY, c, dual)\n",
    "    if (f1 > best_f1):\n",
    "        best_f1 = f1\n",
    "        bestC = c\n",
    "        best_dual = dual\n",
    "    c *= 0.8\n",
    "\n",
    "print(\"The F1 measure = {} \\nC = {}\\nDual = {}\".format(best_f1, bestC, best_dual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the best hyper parameters with C = 0.009223372036854787 and dual = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BBOW) Training F1 Measure of Linear SVM with best hyper-parameter = 0.8435714285714284\n",
      "(BBOW) Validation F1 Measure of Linear SVM with best hyper-parameter = 0.513\n",
      "(BBOW) Testing F1 Measure of Linear SVM with best hyper-parameter = 0.5085\n"
     ]
    }
   ],
   "source": [
    "BBOW_F1_SVM_train = linearSVM(trainX, trainY, trainX, trainY, 0.009223372036854787, False)\n",
    "print(\"(BBOW) Training F1 Measure of Linear SVM with best hyper-parameter = {}\".format(BBOW_F1_SVM_train))\n",
    "BBOW_F1_SVM_valid = linearSVM(trainX, trainY, validX, validY, 0.009223372036854787, False)\n",
    "print(\"(BBOW) Validation F1 Measure of Linear SVM with best hyper-parameter = {}\".format(BBOW_F1_SVM_valid))\n",
    "BBOW_F1_SVM_test = linearSVM(trainX, trainY, testX, testY, 0.009223372036854787, False)\n",
    "print(\"(BBOW) Testing F1 Measure of Linear SVM with best hyper-parameter = {}\".format(BBOW_F1_SVM_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use frequency bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainReviews = getReviews(\"output_datasets/yelp-train.txt\")\n",
    "trainX = buildFreqBOW(trainReviews[0])\n",
    "trainY = trainReviews[1]\n",
    "\n",
    "validReviews = getReviews(\"output_datasets/yelp-valid.txt\")\n",
    "validX = buildFreqBOW(validReviews[0])\n",
    "validY = validReviews[1]\n",
    "\n",
    "testReviews = getReviews(\"output_datasets/yelp-test.txt\")\n",
    "testX = buildFreqBOW(testReviews[0])\n",
    "testY = testReviews[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Native Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianNativeBayes(X_train, y_train, X_test, y_test):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    predict = []\n",
    "    for i in range(len(X_test)):\n",
    "        res = clf.predict([X_test[i]])\n",
    "        predict.append(res)\n",
    "    f1 = metrics.f1_score(y_test, predict, average='micro')\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(FBOW) Training F1 Measure of Gaussian NB = 0.8014285714285714\n",
      "(FBOW) Validation F1 Measure of Gaussian NB = 0.3\n",
      "(FBOW) Testing F1 Measure of Gaussian NB = 0.312\n"
     ]
    }
   ],
   "source": [
    "FBOW_F1_GNB_train = GaussianNativeBayes(trainX, trainY, trainX, trainY)\n",
    "print(\"(FBOW) Training F1 Measure of Gaussian NB = {}\".format(FBOW_F1_GNB_train))\n",
    "FBOW_F1_GNB_valid = GaussianNativeBayes(trainX, trainY, validX, validY)\n",
    "print(\"(FBOW) Validation F1 Measure of Gaussian NB = {}\".format(FBOW_F1_GNB_valid))\n",
    "FBOW_F1_GNB_test = GaussianNativeBayes(trainX, trainY, testX, testY)\n",
    "print(\"(FBOW) Testing F1 Measure of Gaussian NB = {}\".format(FBOW_F1_GNB_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best F1 measure  = 0.408 \n",
      "max_depth = 8 \n",
      "min_sample_split = 0.006782230728489994\n"
     ]
    }
   ],
   "source": [
    "findHyperP_DT(trainX, trainY, validX, validY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the best min_sample_split on the test set with min_sample_split = 0.006782230728489994 and max_depth = 8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(FBOW) Training F1 Measure of Decision Tree with best hyper-parameter = 0.48414285714285715\n",
      "(FBOW) Validation F1 Measure of Decision Tree with best hyper-parameter = 0.408\n",
      "(FBOW) Testing F1 Measure of Decision Tree with best hyper-parameter = 0.416\n"
     ]
    }
   ],
   "source": [
    "FBOW_F1_DT_train = decisionTree(trainX, trainY, trainX, trainY, 0.006782230728489994, 8)\n",
    "print(\"(FBOW) Training F1 Measure of Decision Tree with best hyper-parameter = {}\".format(FBOW_F1_DT_train))\n",
    "FBOW_F1_DT_valid = decisionTree(trainX, trainY, validX, validY, 0.006782230728489994, 8)\n",
    "print(\"(FBOW) Validation F1 Measure of Decision Tree with best hyper-parameter = {}\".format(FBOW_F1_DT_valid))\n",
    "FBOW_F1_DT_test = decisionTree(trainX, trainY, testX, testY, 0.006782230728489994, 8)\n",
    "print(\"(FBOW) Testing F1 Measure of Decision Tree with best hyper-parameter = {}\".format(FBOW_F1_DT_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 measure = 0.508 \n",
      "C = 12.839184645488634\n",
      "Dual = False\n"
     ]
    }
   ],
   "source": [
    "c = 1.0\n",
    "best_f1 = 0\n",
    "bestC = 1.0\n",
    "best_dual = False\n",
    "for i in range(30):\n",
    "    dual = False\n",
    "    f1 = linearSVM(trainX, trainY, validX, validY,c, dual)\n",
    "    if (f1 > best_f1):\n",
    "        best_f1 = f1\n",
    "        bestC = c\n",
    "        best_dual = dual\n",
    "    dual = True\n",
    "    f1 = linearSVM(trainX, trainY, validX, validY, c, dual)\n",
    "    if (f1 > best_f1):\n",
    "        best_f1 = f1\n",
    "        bestC = c\n",
    "        best_dual = dual\n",
    "    c *= 1.2\n",
    "\n",
    "print(\"The F1 measure = {} \\nC = {}\\nDual = {}\".format(best_f1, bestC, best_dual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the best hyper parameters with C = 12.839184645488634 and dual = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(FBOW) Training F1 Measure of Linear SVM with best hyper-parameter = 0.6847142857142857\n",
      "(FBOW) Validation F1 Measure of Linear SVM with best hyper-parameter = 0.508\n",
      "(FBOW) Testing F1 Measure of Linear SVM with best hyper-parameter = 0.508\n"
     ]
    }
   ],
   "source": [
    "FBOW_F1_SVM_train = linearSVM(trainX, trainY, trainX, trainY, 12.839184645488634, False)\n",
    "print(\"(FBOW) Training F1 Measure of Linear SVM with best hyper-parameter = {}\".format(FBOW_F1_SVM_train))\n",
    "FBOW_F1_SVM_valid = linearSVM(trainX, trainY, validX, validY, 12.839184645488634, False)\n",
    "print(\"(FBOW) Validation F1 Measure of Linear SVM with best hyper-parameter = {}\".format(FBOW_F1_SVM_valid))\n",
    "FBOW_F1_SVM_test = linearSVM(trainX, trainY, testX, testY, 12.839184645488634, False)\n",
    "print(\"(FBOW) Testing F1 Measure of Linear SVM with best hyper-parameter = {}\".format(FBOW_F1_SVM_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use IMDB dataset with binary bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainReviews = getReviews(\"output_datasets/IMDB-train.txt\")\n",
    "trainX = buildBinaryBOW(trainReviews[0])\n",
    "trainY = trainReviews[1]\n",
    "\n",
    "validReviews = getReviews(\"output_datasets/IMDB-valid.txt\")\n",
    "validX = buildBinaryBOW(validReviews[0])\n",
    "validY = validReviews[1]\n",
    "\n",
    "testReviews = getReviews(\"output_datasets/IMDB-test.txt\")\n",
    "testX = buildBinaryBOW(testReviews[0])\n",
    "testY = testReviews[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base line classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Random F1 Measure = 0.12429988798207713\n"
     ]
    }
   ],
   "source": [
    "randomClf(trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best smoothing parameter alpha = 0.08589934592000005 \n",
      " F1 measure  = 0.8438312337532493\n"
     ]
    }
   ],
   "source": [
    "findAlpha_BNB(trainX, trainY, validX, validY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the best alpha and predit the test dataset with alpha = 0.08589934592000005 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BBOW) Training F1 Measure of Bernoulli NB with best hyper-parameter = 0.8686929280810505\n",
      "(BBOW) Validation F1 Measure of Bernoulli NB with best hyper-parameter = 0.8438312337532493\n",
      "(BBOW) Testing F1 Measure of Bernoulli NB with best hyper-parameter = 0.8284925588094095\n"
     ]
    }
   ],
   "source": [
    "BBOW_F1_BNB_train = BernoulliNativeBayes(trainX, trainY, trainX, trainY, 0.08589934592000005)\n",
    "print(\"(BBOW) Training F1 Measure of Bernoulli NB with best hyper-parameter = {}\".format(BBOW_F1_BNB_train))\n",
    "BBOW_F1_BNB_valid = BernoulliNativeBayes(trainX, trainY, validX, validY, 0.08589934592000005)\n",
    "print(\"(BBOW) Validation F1 Measure of Bernoulli NB with best hyper-parameter = {}\".format(BBOW_F1_BNB_valid))\n",
    "BBOW_F1_BNB_test = BernoulliNativeBayes(trainX, trainY, testX, testY, 0.08589934592000005)\n",
    "print(\"(BBOW) Testing F1 Measure of Bernoulli NB with best hyper-parameter = {}\".format(BBOW_F1_BNB_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best F1 measure  = 0.6959608078384323 \n",
      "max_depth = 6 \n",
      "min_sample_split = 0.040353606999999986\n"
     ]
    }
   ],
   "source": [
    "findHyperP_DT(trainX, trainY, validX, validY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the best max_depth and min_sample_split on the test set with max_depth = 6 and min_sample_split = 0.04035360699999998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BBOW) Training F1 Measure of Decision Tree with best hyper-parameter = 0.7064587082583483\n",
      "(BBOW) Validation F1 Measure of Decision Tree with best hyper-parameter = 0.6959608078384323\n",
      "(BBOW) Testing F1 Measure of Decision Tree with best hyper-parameter = 0.7058329332693231\n"
     ]
    }
   ],
   "source": [
    "BBOW_F1_DT_train = decisionTree(trainX, trainY, trainX, trainY, 0.04035360699999998, 6)\n",
    "print(\"(BBOW) Training F1 Measure of Decision Tree with best hyper-parameter = {}\".format(BBOW_F1_DT_train))\n",
    "BBOW_F1_DT_valid = decisionTree(trainX, trainY, validX, validY, 0.04035360699999998, 6)\n",
    "print(\"(BBOW) Validation F1 Measure of Decision Tree with best hyper-parameter = {}\".format(BBOW_F1_DT_valid))\n",
    "BBOW_F1_DT_test = decisionTree(trainX, trainY, testX, testY, 0.04035360699999998, 6)\n",
    "print(\"(BBOW) Testing F1 Measure of Decision Tree with best hyper-parameter = {}\".format(BBOW_F1_DT_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find best hyper parameter C and dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 measure = 0.8787242551489702 \n",
      "C = 0.004747561509942996\n",
      "Dual = False\n"
     ]
    }
   ],
   "source": [
    "c = 0.7\n",
    "best_f1 = 0\n",
    "bestC = 1.0\n",
    "best_dual = False\n",
    "for i in range(15):\n",
    "    dual = False\n",
    "    f1 = linearSVM(trainX, trainY, validX, validY,c, dual)\n",
    "    if (f1 > best_f1):\n",
    "        best_f1 = f1\n",
    "        bestC = c\n",
    "        best_dual = dual\n",
    "    dual = True\n",
    "    f1 = linearSVM(trainX, trainY, validX, validY, c, dual)\n",
    "    if (f1 > best_f1):\n",
    "        best_f1 = f1\n",
    "        bestC = c\n",
    "        best_dual = dual\n",
    "    c *= 0.7\n",
    "\n",
    "print(\"The F1 measure = {} \\nC = {}\\nDual = {}\".format(best_f1, bestC, best_dual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the best hyper parameters with C = 0.004747561509942996 and dual = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BBOW) Training F1 Measure of Linear SVM with best hyper-parameter = 0.9470772512164234\n",
      "(BBOW) Validation F1 Measure of Linear SVM with best hyper-parameter = 0.8787242551489702\n",
      "(BBOW) Testing F1 Measure of Linear SVM with best hyper-parameter = 0.874739958393343\n"
     ]
    }
   ],
   "source": [
    "BBOW_F1_SVM_train = linearSVM(trainX, trainY, trainX, trainY, 0.004747561509942996, False)\n",
    "print(\"(BBOW) Training F1 Measure of Linear SVM with best hyper-parameter = {}\".format(BBOW_F1_SVM_train))\n",
    "BBOW_F1_SVM_valid = linearSVM(trainX, trainY, validX, validY, 0.004747561509942996, False)\n",
    "print(\"(BBOW) Validation F1 Measure of Linear SVM with best hyper-parameter = {}\".format(BBOW_F1_SVM_valid))\n",
    "BBOW_F1_SVM_test = linearSVM(trainX, trainY, testX, testY, 0.004747561509942996, False)\n",
    "print(\"(BBOW) Testing F1 Measure of Linear SVM with best hyper-parameter = {}\".format(BBOW_F1_SVM_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use frequency bag of word for IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainReviews = getReviews(\"output_datasets/IMDB-train.txt\")\n",
    "trainX = buildFreqBOW(trainReviews[0])\n",
    "trainY = trainReviews[1]\n",
    "\n",
    "validReviews = getReviews(\"output_datasets/IMDB-valid.txt\")\n",
    "validX = buildFreqBOW(validReviews[0])\n",
    "validY = validReviews[1]\n",
    "\n",
    "testReviews = getReviews(\"output_datasets/IMDB-test.txt\")\n",
    "testX = buildFreqBOW(testReviews[0])\n",
    "testY = testReviews[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Native Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(FBOW) Training F1 Measure of Gaussian NB = 0.8565620209291475\n",
      "(FBOW) Validation F1 Measure of Gaussian NB = 0.7521495700859829\n",
      "(FBOW) Testing F1 Measure of Gaussian NB = 0.681148983837414\n"
     ]
    }
   ],
   "source": [
    "FBOW_F1_GNB_train = GaussianNativeBayes(trainX, trainY, trainX, trainY)\n",
    "print(\"(FBOW) Training F1 Measure of Gaussian NB = {}\".format(FBOW_F1_GNB_train))\n",
    "FBOW_F1_GNB_valid = GaussianNativeBayes(trainX, trainY, validX, validY)\n",
    "print(\"(FBOW) Validation F1 Measure of Gaussian NB = {}\".format(FBOW_F1_GNB_valid))\n",
    "FBOW_F1_GNB_test = GaussianNativeBayes(trainX, trainY, testX, testY)\n",
    "print(\"(FBOW) Testing F1 Measure of Gaussian NB = {}\".format(FBOW_F1_GNB_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best F1 measure  = 0.6993601279744052 \n",
      "max_depth = 6 \n",
      "min_sample_split = 0.49\n"
     ]
    }
   ],
   "source": [
    "findHyperP_DT(trainX, trainY, validX, validY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the best min_sample_split on the test set with min_sample_split = 0.49 and max_depth = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(FBOW) Training F1 Measure of Decision Tree with best hyper-parameter = 0.706125441578351\n",
      "(FBOW) Validation F1 Measure of Decision Tree with best hyper-parameter = 0.6993601279744052\n",
      "(FBOW) Testing F1 Measure of Decision Tree with best hyper-parameter = 0.7032325172027525\n"
     ]
    }
   ],
   "source": [
    "FBOW_F1_DT_train = decisionTree(trainX, trainY, trainX, trainY, 0.49, 6)\n",
    "print(\"(FBOW) Training F1 Measure of Decision Tree with best hyper-parameter = {}\".format(FBOW_F1_DT_train))\n",
    "FBOW_F1_DT_valid = decisionTree(trainX, trainY, validX, validY, 0.49, 6)\n",
    "print(\"(FBOW) Validation F1 Measure of Decision Tree with best hyper-parameter = {}\".format(FBOW_F1_DT_valid))\n",
    "FBOW_F1_DT_test = decisionTree(trainX, trainY, testX, testY, 0.49, 6)\n",
    "print(\"(FBOW) Testing F1 Measure of Decision Tree with best hyper-parameter = {}\".format(FBOW_F1_DT_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find best hyper parameter C and dual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 measure = 0.876124775044991 \n",
      "C = 31.947999937062274\n",
      "Dual = False\n"
     ]
    }
   ],
   "source": [
    "c = 1.0\n",
    "best_f1 = 0\n",
    "bestC = 1.0\n",
    "best_dual = False\n",
    "for i in range(20):\n",
    "    dual = False\n",
    "    f1 = linearSVM(trainX, trainY, validX, validY,c, dual)\n",
    "    if (f1 > best_f1):\n",
    "        best_f1 = f1\n",
    "        bestC = c\n",
    "        best_dual = dual\n",
    "    dual = True\n",
    "    f1 = linearSVM(trainX, trainY, validX, validY, c, dual)\n",
    "    if (f1 > best_f1):\n",
    "        best_f1 = f1\n",
    "        bestC = c\n",
    "        best_dual = dual\n",
    "    c *= 1.2\n",
    "\n",
    "print(\"The F1 measure = {} \\nC = {}\\nDual = {}\".format(best_f1, bestC, best_dual))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the best hyper parameters with C = 31.947999937062274 and dual = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(FBOW) Training F1 Measure of Linear SVM with best hyper-parameter = 0.9186829300806505\n",
      "(FBOW) Validation F1 Measure of Linear SVM with best hyper-parameter = 0.876124775044991\n",
      "(FBOW) Testing F1 Measure of Linear SVM with best hyper-parameter = 0.8739398303728596\n"
     ]
    }
   ],
   "source": [
    "FBOW_F1_SVM_train = linearSVM(trainX, trainY, trainX, trainY, 31.947999937062274, False)\n",
    "print(\"(FBOW) Training F1 Measure of Linear SVM with best hyper-parameter = {}\".format(FBOW_F1_SVM_train))\n",
    "FBOW_F1_SVM_valid = linearSVM(trainX, trainY, validX, validY, 31.947999937062274, False)\n",
    "print(\"(FBOW) Validation F1 Measure of Linear SVM with best hyper-parameter = {}\".format(FBOW_F1_SVM_valid))\n",
    "FBOW_F1_SVM_test = linearSVM(trainX, trainY, testX, testY, 31.947999937062274, False)\n",
    "print(\"(FBOW) Testing F1 Measure of Linear SVM with best hyper-parameter = {}\".format(FBOW_F1_SVM_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
